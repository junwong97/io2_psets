{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "twenty-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions, Random, Plots, DataFrames, Optim, Statistics\n",
    "using LinearAlgebra, StatsFuns, ScikitLearn, CSV, SparseArrays, GLM, LaTeXTabulars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "molecular-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids = DataFrame(CSV.File(\"../Data/bids.csv\"));\n",
    "items = DataFrame(CSV.File(\"../Data/items.csv\"));\n",
    "attributes = DataFrame(CSV.File(\"../Data/sparse_attributes.csv\"));\n",
    "sparse_attributes = sparse(attributes[!,1], attributes[!,2], attributes[!,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-cycle",
   "metadata": {},
   "source": [
    "# 1. Some summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "played-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids[!,:log_bid_value] = log.(bids[!,:bid_value])\n",
    "gbids = groupby(bids, :item_num)\n",
    "gbids = combine(gbids, nrow => :num_bids);\n",
    "bids_sum = combine(bids, :log_bid_value => mean, :log_bid_value => std, :log_bid_value => median, :log_bid_value => maximum, :log_bid_value => minimum);\n",
    "gbids_sum = combine(gbids, :num_bids => mean, :num_bids => std, :num_bids => median, :num_bids => maximum, :num_bids => minimum);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "improved-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_tabular(\"output/ps3_q3_part1summary.tex\",\n",
    "              Tabular(\"cccccc\"),\n",
    "              [Rule(:top),\n",
    "               [\"\", \"Mean\", \"SD\", \"Median\", \"Maximum\", \"Minimum\"],\n",
    "               Rule(:mid),\n",
    "               hcat(\"Log Bid Value\", round.(Array(bids_sum), digits=3)),\n",
    "               hcat(\"Number of Bids\", round.(Array(gbids_sum), digits=3)),\n",
    "               Rule(:bottom)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-hometown",
   "metadata": {},
   "source": [
    "# 2. Estimate $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mental-average",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put into dataframe\n",
    "items.row_num = 1:nrow(items)\n",
    "items = innerjoin(gbids, items, on=\"item_num\");\n",
    "bids = innerjoin(bids, items, on=\"item_num\")\n",
    "attributes = DataFrame(Matrix{Float64}(sparse_attributes), :auto)\n",
    "attributes.row_num = 1:nrow(attributes)\n",
    "attribute_bids = innerjoin(bids, attributes, on=\"row_num\");\n",
    "attribute_bids.enter .= 1 #since we observe all bids \n",
    "attribute_bids.difference = attribute_bids[!,:pred_n_participant] .- attribute_bids[!,:num_bids];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aquatic-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to create a dataframe that has pred_n_participant - num_bidders with enter = 0\n",
    "dflist = []\n",
    "for x in items.item_num\n",
    "    rownum = attribute_bids[attribute_bids[!,:item_num].==x, :row_num][1]\n",
    "    rep = Integer(attribute_bids[attribute_bids[!,:item_num].==x, :difference][1])\n",
    "\n",
    "    # build my columns\n",
    "    if rep > 0 \n",
    "        chars = repeat(DataFrame(attribute_bids[attribute_bids[!,:item_num].==x, [:item_num, :pred_n_participant]][1,:]), rep)\n",
    "        atts = repeat(attributes[attributes[!,:row_num].==rownum,:], rep)\n",
    "        entry = DataFrame(enter=repeat([0], rep))\n",
    "        df = hcat(chars, atts, entry)\n",
    "\n",
    "        push!(dflist, df)\n",
    "    end  \n",
    "end\n",
    "nobids = reduce(vcat, dflist)\n",
    "attribute_bids = sort(vcat(nobids, attribute_bids, cols=:union), :item_num);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "serial-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probit to get inverse mills ratio \n",
    "att = sum(Term.(Symbol.(names(attribute_bids[:, Not([:log_bid_value, :bid_value, :row_num, :item_num, :pred_n_participant, :enter, :num_bids, :difference])]))))\n",
    "probit = glm(Term(:enter) ~ att, attribute_bids, Binomial(), ProbitLink())\n",
    "attribute_bids.probit_fit = GLM.predict(probit, attribute_bids[:, Not([:log_bid_value, :bid_value, :row_num, :item_num, :pred_n_participant, :enter, :num_bids, :difference])]);\n",
    "attribute_bids.imr = pdf(Normal(), attribute_bids.probit_fit) ./ cdf(Normal(), attribute_bids.probit_fit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "varied-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sparse(Array(attribute_bids[attribute_bids[:,:enter].==1, names(attribute_bids, Not([:log_bid_value, :bid_value, :row_num, :item_num, :pred_n_participant, :enter, :num_bids, :difference]))]));\n",
    "Y = Array(attribute_bids[attribute_bids[:,:enter].==1,:log_bid_value]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "integral-ancient",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge llvm-openmp` in root environment\n",
      "└ @ Conda /Users/junwong/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2193714288249031"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1: Linear regression\n",
    "@sk_import linear_model: LinearRegression\n",
    "ols = ScikitLearn.fit!(LinearRegression(), X, Y)\n",
    "Ŷ = ScikitLearn.predict(ols, X);\n",
    "ols_mse = mean((Ŷ .- Y).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "earned-judges",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge llvm-openmp` in root environment\n",
      "└ @ Conda /Users/junwong/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Lasso MSE is 1.2264922269223795 with alpha 1.160438988948313e-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=8.338e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=7.571e-05, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=6.081e-05, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=3.922e-05, with an active set of 226 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=3.553e-05, with an active set of 245 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 314 iterations, i.e. alpha=2.346e-05, with an active set of 310 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=1.780e-05, with an active set of 348 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.377e-05, with an active set of 384 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/junwong/.julia/conda/3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 430 iterations, alpha=9.528e-06, previous alpha=9.426e-06, with an active set of 423 regressors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Lasso\n",
    "@sk_import linear_model: LassoLarsIC;\n",
    "lasso=ScikitLearn.fit!(LassoLarsIC(criterion=\"aic\"), X, Y);\n",
    "Ŷ = ScikitLearn.predict(lasso, X)\n",
    "lasso_mse = mean((Ŷ .- Y).^2)\n",
    "println(\"Lasso MSE is \", lasso_mse, \" with alpha \", lasso.alphas_[argmin(lasso.criterion_)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "miniature-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge llvm-openmp` in root environment\n",
      "└ @ Conda /Users/junwong/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5800010103208214"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 3: Neural net \n",
    "@sk_import neural_network: MLPRegressor\n",
    "clf = MLPRegressor(hidden_layer_sizes=(250))\n",
    "nn_reg = ScikitLearn.fit!(clf, X, Y)\n",
    "Ŷ = ScikitLearn.predict(nn_reg, X)\n",
    "nn_mse = mean((Ŷ .- Y).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "floating-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_tabular(\"output/ps3_q3_mse.tex\",\n",
    "              Tabular(\"cc\"),\n",
    "              [Rule(:top),\n",
    "               [\"\", \"MSE\"],\n",
    "               Rule(:mid),\n",
    "               [\"OLS\", round(ols_mse, digits=3)],\n",
    "               [\"Lasso\", round(lasso_mse, digits=3)],\n",
    "               [\"Neural Net\", round(nn_mse, digits=3)],\n",
    "               Rule(:bottom)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "following-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenized log bids\n",
    "attribute_bids = attribute_bids[attribute_bids[:,:enter].==1,:]\n",
    "attribute_bids.resid_bid = Y - Ŷ;\n",
    "\n",
    "highest_bids = combine(groupby(attribute_bids, :item_num)) do sdf\n",
    "       first(sort(sdf, :resid_bid, rev=true), 2)[:,[:item_num, :pred_n_participant, :resid_bid]]\n",
    "       end\n",
    "# reshape into two columns\n",
    "highest_bids.ranking = repeat([\"first\", \"second\"], Integer(size(highest_bids,1)/2));\n",
    "highest_bids = unstack(highest_bids, [:item_num, :pred_n_participant], :ranking, :resid_bid)\n",
    "\n",
    "X_3 = Array(highest_bids[2 .<= highest_bids[!,:pred_n_participant] .<= 3, [:first, :second]]);\n",
    "X_7 = Array(highest_bids[4 .<= highest_bids[!,:pred_n_participant] .<= 7, [:first, :second]]);\n",
    "X_8 = Array(highest_bids[8 .<= highest_bids[!,:pred_n_participant], [:first, :second]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "professional-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_sum = combine(attribute_bids, :resid_bid => mean, :resid_bid => std, :resid_bid => median, :resid_bid => maximum, :resid_bid => minimum);\n",
    "latex_tabular(\"output/ps3_q3_part7summary.tex\",\n",
    "              Tabular(\"cccccc\"),\n",
    "              [Rule(:top),\n",
    "               [\"\", \"Mean\", \"SD\", \"Median\", \"Maximum\", \"Minimum\"],\n",
    "               Rule(:mid),\n",
    "               hcat(\"Homogenized Log Bid\", round.(Array(bids_sum), digits=3)),\n",
    "               Rule(:bottom)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-basis",
   "metadata": {},
   "source": [
    "# 3. Song (2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rolled-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge llvm-openmp` in root environment\n",
      "└ @ Conda /Users/junwong/.julia/packages/Conda/x2UxR/src/Conda.jl:127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@sk_import mixture: GaussianMixture \n",
    "\n",
    "all_cdf = []\n",
    "all_pdf = []\n",
    "for x in [X_3, X_7, X_8]\n",
    "    mixing = ScikitLearn.fit!(GaussianMixture(n_components=3), x) \n",
    "    blah = hcat(-2:0.01:2, -2:0.01:2)\n",
    "    pdf = exp.(score_samples(mixing, blah))\n",
    "    cdf = cumsum(pdf) ./ maximum(cumsum(pdf))\n",
    "    push!(all_pdf, pdf)\n",
    "    push!(all_cdf, cdf)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "boolean-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/junwong/Documents/io2_psets/ps3/output/ps3_q3_bids_cdf.pdf\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(-2:0.01:2, all_cdf[1], width=2, labels = \"2-3 participants\")\n",
    "plot!(-2:0.01:2, all_cdf[2], width=2, labels = \"4-7 participants\")\n",
    "plot!(-2:0.01:2, all_cdf[3], width=2, labels =\"8+ participants\", legend = :topleft,\n",
    "      xlabel=\"Homogenized Log Bid\", ylabel=\"F(Homogenized Log Bid)\")\n",
    "savefig(\"output/ps3_q3_bids_cdf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "moving-reservation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/junwong/Documents/io2_psets/ps3/output/ps3_q3_reserve_prices.pdf\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot optimal reserve price \n",
    "iter_v = 1\n",
    "optimal_price = zeros(length(-2:0.01:2),2)\n",
    "valuation_range = -2:0.01:2\n",
    "\n",
    "# you want to minimize v_seller - (r + 1-F(r)/f(r))\n",
    "# here I just do a really coarse search over a grid from -2 -> 2 by 0:01\n",
    "for v in 1:length(valuation_range)\n",
    "    minim_list = []\n",
    "    for r in 1:length(valuation_range)\n",
    "        push!(minim_list, abs(valuation_range[v] - valuation_range[r] + (1-all_cdf[1][r])/all_pdf[1][r]))\n",
    "    end\n",
    "    optimal_price[v, 1] = valuation_range[argmin(minim_list)]\n",
    "    optimal_price[v, 2] = minimum(minim_list)\n",
    "    iter_v +=1\n",
    "end\n",
    "\n",
    "plot(exp.(valuation_range), exp.(optimal_price[:,1]), legend=false, \n",
    "     width=1.5, xlabel=\"Seller Valuation\", ylabel=\"Optimal Reserve Price\")\n",
    "savefig(\"output/ps3_q3_reserve_prices.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-lodging",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
